# -*- coding: utf-8 -*-
"""Diabetes-LogisticRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lC-eNA9bXl5jmWAyqo-38kxw3GCtzrvx
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score
def run_logistic_regression():
    df = pd.read_csv('diabetes.csv')

   #every important col with unrealistic zero-values getting in a variable
    cols_with_zeros = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']

    #I change the zero-values in my selected cols to empty values with replace(0, np.nan)
    df[cols_with_zeros] = df[cols_with_zeros].replace(0, np.nan)

    #I fill every empty value with the mean of the other values
    df[cols_with_zeros] = df[cols_with_zeros].fillna(df.mean())
    #to avoid scaling problems, I am scaling the features of X
    X = StandardScaler().fit_transform(df.drop("Outcome", axis=1))
    y = df["Outcome"].values

    #I split my dataset into 80% to train and 20% to test data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    results = []
    #I am defining the model with LogisticRegression
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    #the parameters show me the evaluation of the model or the models
    metrics = {
            #shows me the accuracy of every true predicted classification
            "accuracy": accuracy_score(y_test, y_pred),
            #recall shows me how many correct predictions my model makes in relation to the really correct ones
            "recall": recall_score(y_test, y_pred),
            #shows me the Accuracy of positiv predictions
            "precision": precision_score(y_test, y_pred),
            #combined precision and recall, it is important for unbalanced datasets
            "f1_score": f1_score(y_test, y_pred)
            }
    results.append(metrics)

    return results